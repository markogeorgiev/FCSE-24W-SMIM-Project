{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Graph Type and Purpose\n",
    "\n",
    "You are constructing a **heterogeneous directed multigraph** using `NetworkX`’s `MultiDiGraph()` to model complex cyber network interactions. This design is particularly effective for advanced cybersecurity applications such as:\n",
    "\n",
    "- **Graph-based threat detection**\n",
    "- **Anomaly identification in multi-modal behaviors**\n",
    "- **Learning embeddings for heterogeneous entities**\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "- **Heterogeneous nodes**  \n",
    "  Represents diverse entities: IP addresses, domain names, HTTP URIs, SSL certificate subjects/issuers, protocol violation types, etc.\n",
    "\n",
    "- **Multi-view relationships**  \n",
    "  Multiple directed edge types between the same pair of nodes allow different interaction views (e.g., flows, DNS queries, HTTP requests).\n",
    "\n",
    "- **Directed edges**  \n",
    "  Encode **temporal or causal flow** (e.g., `src_ip ➝ dst_ip`, `IP ➝ domain`), reflecting who initiated what.\n",
    "\n",
    "# Node Types (Entities)\n",
    "\n",
    "Each node represents a real-world entity, extracted from one or more dataset columns:\n",
    "\n",
    "| Node Type         | Source Column(s)    | Description                                                                 |\n",
    "|-------------------|---------------------|-----------------------------------------------------------------------------|\n",
    "| **IP Address**     | `src_ip`, `dst_ip`  | Devices or interfaces on the network (e.g., `192.168.1.37`).                |\n",
    "| **Domain Name**    | `dns_query`         | Fully qualified domain names queried by IPs (e.g., `www.example.com`).      |\n",
    "| **HTTP URI**       | `http_uri`          | HTTP resource paths (e.g., `/login`, `/index.html`).                        |\n",
    "| **SSL Subject**    | `ssl_subject`       | Distinguished Name of the certificate subject (e.g., `/C=US/O=Let's Encrypt`). |\n",
    "| **SSL Issuer**     | `ssl_issuer`        | Distinguished Name of the certificate issuer (e.g., `/C=US/O=Google Trust Services`). |\n",
    "| **Protocol Violation** | `weird_name`     | Descriptive label of detected anomalies (e.g., `bad_TCP_checksum`).         |\n",
    "\n",
    "---\n",
    "\n",
    "# Edge Types (Views)\n",
    "\n",
    "Each directed edge represents an interaction or behavioral relationship, often enriched with protocol metadata:\n",
    "\n",
    "## 1. `flow` — (IP ➝ IP)\n",
    "\n",
    "Represents a network flow between two IP addresses.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `dst_ip`  \n",
    "- **Attributes:**\n",
    "  - `proto`, `service`, `duration`, `conn_state`\n",
    "  - `src_bytes`, `dst_bytes`\n",
    "  - `label`, `attack_type`\n",
    "\n",
    "**Usefulness:**  \n",
    "Defines the **structural backbone** of the graph, enabling analysis of traffic patterns and attack topologies.\n",
    "\n",
    "## 2. `dns_query` — (IP ➝ Domain Name)\n",
    "\n",
    "Represents a DNS lookup initiated by a host.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `dns_query`  \n",
    "- **Attributes:**\n",
    "  - `qclass`, `qtype`, `rcode`\n",
    "  - `dns_AA`, `dns_RD`, `dns_RA`, `dns_rejected`\n",
    "\n",
    "**Usefulness:**  \n",
    "Reveals **host intent** and can indicate access to suspicious or malicious domains.\n",
    "\n",
    "## 3. `http_request` — (IP ➝ HTTP URI)\n",
    "\n",
    "Captures web resource requests made by a host.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `http_uri`  \n",
    "- **Attributes:**\n",
    "  - `method`, `version`, `status_code`\n",
    "  - `trans_depth`, `req_body_len`, `resp_body_len`\n",
    "  - `user_agent`, `orig_mime`, `resp_mime`\n",
    "\n",
    "**Usefulness:**  \n",
    "Reflects **web behavior**; useful for detecting scanning, reconnaissance, and probing activity.\n",
    "\n",
    "## 4. `protocol_violation` — (IP ➝ Violation Label)\n",
    "\n",
    "Links an IP to a protocol anomaly observed during communication.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `weird_name`  \n",
    "- **Attributes:**\n",
    "  - `weird_addl`, `weird_notice`\n",
    "\n",
    "**Usefulness:**  \n",
    "Highlights **anomalous or misconfigured hosts**. Many such events are early indicators of compromise or malicious activity.\n",
    "\n",
    "# Semantic Graph Properties\n",
    "\n",
    "- **IP nodes are central:**  \n",
    "  Most interaction types originate from or are directed to IP addresses, making them critical in graph topology.\n",
    "\n",
    "- **Multi-modal behavioral modeling:**  \n",
    "  Combines HTTP, DNS, SSL, and flow-level information into one unified representation.\n",
    "\n",
    "- **Multi-view learning ready:**  \n",
    "  The graph supports training models on **protocol-specific subgraphs or jointly across views**.\n",
    "\n",
    "- **Temporal/causal interpretation:**  \n",
    "  Directed edges preserve **who initiated the interaction**, enabling traceability and behavioral profiling."
   ],
   "id": "54dcff684f4eaa0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Grid Search "
   ],
   "id": "da6d540e1af24f20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T18:06:52.309386Z",
     "start_time": "2025-05-07T18:06:42.575274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "utils_path = os.path.join(parent_dir, \"project_utils\")\n",
    "sys.path.append(utils_path)\n",
    "\n",
    "from project_utils import graph_creator_b_c"
   ],
   "id": "5a0b817c7bed6896",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T18:07:23.236673Z",
     "start_time": "2025-05-07T18:06:53.198631Z"
    }
   },
   "cell_type": "code",
   "source": "G, df = graph_creator_b_c.create_graph_from_file('../datasets/train_test_network.csv')",
   "id": "16190ca1c5f2dfcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph built with 1605 nodes and 2554 edges.\n",
      "Edge types (views) include: {'flow', 'ssl_subject', 'dns_query', 'protocol_violation', 'ssl_issuer', 'http_request'}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T18:07:32.352244Z",
     "start_time": "2025-05-07T18:07:32.269175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert flow_G (DiGraph) to PyG format\n",
    "ip_nodes = [n for n in G.nodes if isinstance(n, str) and '.' in n]\n",
    "\n",
    "node_to_idx = {node: i for i, node in enumerate(ip_nodes)}\n",
    "edge_index = []\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for node in ip_nodes:\n",
    "    out_deg = len([1 for _, _, k in G.out_edges(node, keys=True) if k == \"flow\"])\n",
    "    in_deg = len([1 for _, _, k in G.in_edges(node, keys=True) if k == \"flow\"])\n",
    "\n",
    "    features.append([in_deg, out_deg])\n",
    "\n",
    "    label = \"Normal\"\n",
    "    for _, _, k, d in G.out_edges(node, keys=True, data=True):\n",
    "        if k == \"flow\" and d.get(\"label\"):\n",
    "            label = \"Attack\" if str(d[\"label\"]).lower() != \"normal\" else \"Normal\"\n",
    "            break\n",
    "    labels.append(label)\n",
    "\n",
    "# Encode features and labels\n",
    "X = StandardScaler().fit_transform(features)\n",
    "y = LabelEncoder().fit_transform(labels)\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Build edge index\n",
    "for u, v in G.edges():\n",
    "    if u in node_to_idx and v in node_to_idx:\n",
    "        edge_index.append([node_to_idx[u], node_to_idx[v]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Define PyG Data\n",
    "data = Data(x=X, edge_index=edge_index, y=y)\n",
    "\n",
    "# Split train/test\n",
    "torch.manual_seed(42)\n",
    "num_nodes = data.num_nodes\n",
    "perm = torch.randperm(num_nodes)\n",
    "train_idx = perm[:int(0.8 * num_nodes)]\n",
    "test_idx = perm[int(0.8 * num_nodes):]\n",
    "\n",
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train_idx] = True\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test_idx] = True\n",
    "\n",
    "\n",
    "# Convert flow_G (DiGraph) to PyG format\n",
    "ip_nodes = [n for n in G.nodes if isinstance(n, str) and '.' in n]\n",
    "\n",
    "node_to_idx = {node: i for i, node in enumerate(ip_nodes)}\n",
    "edge_index = []\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for node in ip_nodes:\n",
    "    out_deg = len([1 for _, _, k in G.out_edges(node, keys=True) if k == \"flow\"])\n",
    "    in_deg = len([1 for _, _, k in G.in_edges(node, keys=True) if k == \"flow\"])\n",
    "\n",
    "    features.append([in_deg, out_deg])\n",
    "\n",
    "    label = \"Normal\"\n",
    "    for _, _, k, d in G.out_edges(node, keys=True, data=True):\n",
    "        if k == \"flow\" and d.get(\"label\"):\n",
    "            label = \"Attack\" if str(d[\"label\"]).lower() != \"normal\" else \"Normal\"\n",
    "            break\n",
    "    labels.append(label)\n",
    "\n",
    "# Encode features and labels\n",
    "X = StandardScaler().fit_transform(features)\n",
    "y = LabelEncoder().fit_transform(labels)\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Build edge index\n",
    "for u, v in G.edges():\n",
    "    if u in node_to_idx and v in node_to_idx:\n",
    "        edge_index.append([node_to_idx[u], node_to_idx[v]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Define PyG Data\n",
    "data = Data(x=X, edge_index=edge_index, y=y)\n",
    "\n",
    "# Split train/test\n",
    "torch.manual_seed(42)\n",
    "num_nodes = data.num_nodes\n",
    "perm = torch.randperm(num_nodes)\n",
    "train_idx = perm[:int(0.8 * num_nodes)]\n",
    "test_idx = perm[int(0.8 * num_nodes):]\n",
    "\n",
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train_idx] = True\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test_idx] = True\n"
   ],
   "id": "76e4e0112ee59f0c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T18:08:51.221517Z",
     "start_time": "2025-05-07T18:08:41.222279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, data, train_mask, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def test(model, data, test_mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        preds = logits[test_mask].argmax(dim=1).cpu()\n",
    "        labels = data.y[test_mask].cpu()\n",
    "\n",
    "    return (\n",
    "        accuracy_score(labels, preds),\n",
    "        precision_score(labels, preds, zero_division=0),\n",
    "        recall_score(labels, preds, zero_division=0),\n",
    "        f1_score(labels, preds, zero_division=0),\n",
    "    )\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "\n",
    "def run_holdout(data, test_sizes=None):\n",
    "    if test_sizes is None:\n",
    "        test_sizes = [0.1, 0.3, 0.5]\n",
    "    results = []\n",
    "    X = data.x.cpu().numpy()\n",
    "    y = data.y.cpu().numpy()\n",
    "\n",
    "    for test_size in test_sizes:\n",
    "        train_idx, test_idx = train_test_split(\n",
    "            range(len(y)), test_size=test_size, stratify=y, random_state=42\n",
    "        )\n",
    "        train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "        test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "        train_mask[train_idx] = True\n",
    "        test_mask[test_idx] = True\n",
    "\n",
    "        model = GraphSAGE(data.num_node_features, 32, int(data.y.max().item()) + 1).to(data.x.device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(100):\n",
    "            train(model, data, train_mask, optimizer, criterion)\n",
    "\n",
    "        acc, prec, rec, f1 = test(model, data, test_mask)\n",
    "        label = f\"{int((1 - test_size) * 100)}/{int(test_size * 100)}\"\n",
    "        results.append((label, acc, prec, rec, f1))\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_cv(data, splits=None):\n",
    "    if splits is None:\n",
    "        splits = [5, 10]\n",
    "    results = []\n",
    "    X = data.x.cpu().numpy()\n",
    "    y = data.y.cpu().numpy()\n",
    "\n",
    "    for k in splits:\n",
    "        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        accs, precs, recs, f1s = [], [], [], []\n",
    "\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "            test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "            train_mask[train_idx] = True\n",
    "            test_mask[test_idx] = True\n",
    "\n",
    "            model = GraphSAGE(data.num_node_features, 32, int(data.y.max().item()) + 1).to(data.x.device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            for epoch in range(100):\n",
    "                train(model, data, train_mask, optimizer, criterion)\n",
    "\n",
    "            acc, prec, rec, f1 = test(model, data, test_mask)\n",
    "            accs.append(acc)\n",
    "            precs.append(prec)\n",
    "            recs.append(rec)\n",
    "            f1s.append(f1)\n",
    "\n",
    "        results.append((str(k), sum(accs) / k, sum(precs) / k, sum(recs) / k, sum(f1s) / k))\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run evaluations\n",
    "holdout_results = run_holdout(data)\n",
    "cv_results = run_cv(data)\n",
    "\n",
    "print(\"Split/CV,Accuracy,precision,recal,f1-score\")\n",
    "for r in holdout_results + cv_results:\n",
    "    print(f\"{r[0]},{r[1]:.4f},{r[2]:.4f},{r[3]:.4f},{r[4]:.4f}\")"
   ],
   "id": "6a4ee85fae72f804",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split/CV,Accuracy,precision,recal,f1-score\n",
      "90/10,0.9925,0.9924,1.0000,0.9962\n",
      "70/30,0.9874,0.9874,1.0000,0.9936\n",
      "50/50,0.9909,0.9909,1.0000,0.9954\n",
      "5,0.9894,0.9909,0.9985,0.9947\n",
      "10,0.9894,0.9909,0.9985,0.9947\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# WTF IS THIS",
   "id": "67ab688f51787c70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CV and Grid-Search for GCN",
   "id": "a153701df99d133e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T18:13:09.819093Z",
     "start_time": "2025-05-07T18:12:18.576143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# GCN Model Definition\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Train function (no class weighting needed since we balanced the folds)\n",
    "def train(model, data, train_idx, test_idx, epochs=100, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.train_mask[train_idx] = True\n",
    "    data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.test_mask[test_idx] = True\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        pred = logits[data.test_mask].argmax(dim=1)\n",
    "        true = data.y[data.test_mask]\n",
    "        report = classification_report(true.cpu(), pred.cpu(), target_names=[\"Normal\", \"Attack\"], output_dict=True,\n",
    "                                       zero_division=0)\n",
    "        return report['accuracy'], report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "# Create balanced dataset (as before)\n",
    "normal_idx = (y == 0).nonzero(as_tuple=True)[0]\n",
    "attack_idx = (y == 1).nonzero(as_tuple=True)[0]\n",
    "num_normals = len(normal_idx)\n",
    "undersampled_attack_idx = attack_idx[torch.randperm(len(attack_idx))[:num_normals]]\n",
    "balanced_idx = torch.cat([normal_idx, undersampled_attack_idx])\n",
    "balanced_idx = balanced_idx[torch.randperm(len(balanced_idx))]\n",
    "\n",
    "X_np = data.x[balanced_idx].cpu().numpy()  # just to satisfy StratifiedKFold\n",
    "y_np = y[balanced_idx].cpu().numpy()\n",
    "\n",
    "# Grid Search with Cross-Validation\n",
    "hidden_sizes = [8, 16]\n",
    "learning_rates = [0.02, 0.03, 0.05]\n",
    "epochs_list = [50, 100, 200]\n",
    "grid = list(product(hidden_sizes, learning_rates, epochs_list))\n",
    "\n",
    "best_f1 = -1\n",
    "best_params = None\n",
    "\n",
    "for hidden, lr, epochs in grid:\n",
    "    fold_f1s = []\n",
    "    fold_acc = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx_np, test_idx_np in skf.split(X_np, y_np):\n",
    "        train_idx = balanced_idx[train_idx_np]\n",
    "        test_idx = balanced_idx[test_idx_np]\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "        model = GCN(2, hidden, 2)\n",
    "        acc, f1 = train(model, data, train_idx, test_idx, epochs=epochs, lr=lr)\n",
    "        fold_f1s.append(f1)\n",
    "        fold_acc.append(acc)\n",
    "\n",
    "    avg_f1 = np.mean(fold_f1s)\n",
    "    avg_acc = np.mean(fold_acc)\n",
    "    print(f\"GCN(hid={hidden}, lr={lr}, epochs={epochs}) → CV acc: {avg_acc:.4f}, F1: {avg_f1:.4f}\")\n",
    "\n",
    "    if avg_f1 > best_f1:\n",
    "        best_f1 = avg_f1\n",
    "        best_params = (hidden, lr, epochs)\n",
    "\n",
    "print(\n",
    "    f\"\\nBest GCN config: hidden={best_params[0]}, lr={best_params[1]}, epochs={best_params[2]} with CV F1={best_f1:.4f}\")"
   ],
   "id": "580ecc85872b18b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(hid=8, lr=0.02, epochs=50) → CV acc: 0.7393, F1: 0.7216\n",
      "GCN(hid=8, lr=0.02, epochs=100) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=8, lr=0.02, epochs=200) → CV acc: 0.7393, F1: 0.7276\n",
      "GCN(hid=8, lr=0.03, epochs=50) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=8, lr=0.03, epochs=100) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=8, lr=0.03, epochs=200) → CV acc: 0.7143, F1: 0.7022\n",
      "GCN(hid=8, lr=0.05, epochs=50) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=8, lr=0.05, epochs=100) → CV acc: 0.7929, F1: 0.7794\n",
      "GCN(hid=8, lr=0.05, epochs=200) → CV acc: 0.6893, F1: 0.6743\n",
      "GCN(hid=16, lr=0.02, epochs=50) → CV acc: 0.7143, F1: 0.6949\n",
      "GCN(hid=16, lr=0.02, epochs=100) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=16, lr=0.02, epochs=200) → CV acc: 0.7357, F1: 0.7184\n",
      "GCN(hid=16, lr=0.03, epochs=50) → CV acc: 0.7643, F1: 0.7556\n",
      "GCN(hid=16, lr=0.03, epochs=100) → CV acc: 0.7393, F1: 0.7276\n",
      "GCN(hid=16, lr=0.03, epochs=200) → CV acc: 0.7393, F1: 0.7276\n",
      "GCN(hid=16, lr=0.05, epochs=50) → CV acc: 0.7643, F1: 0.7470\n",
      "GCN(hid=16, lr=0.05, epochs=100) → CV acc: 0.7393, F1: 0.7276\n",
      "GCN(hid=16, lr=0.05, epochs=200) → CV acc: 0.7393, F1: 0.7327\n",
      "\n",
      "Best GCN config: hidden=8, lr=0.02, epochs=100 with CV F1=0.7810\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grid Search with CV on GraphSAGE",
   "id": "d82720b16cecb9ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import classification_report\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# GraphSAGE Model Definition\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Compute class weights based on imbalance\n",
    "def get_class_weights(y):\n",
    "    counts = torch.bincount(y)\n",
    "    weights = 1.0 / counts.float()\n",
    "    weights = weights * (len(y) / weights.sum())  # normalize\n",
    "    return weights\n",
    "\n",
    "\n",
    "# Training Function (same logic)\n",
    "def train(model, data, epochs=100, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    class_weights = get_class_weights(data.y[data.train_mask]).to(data.x.device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask], weight=class_weights)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        pred = logits[data.test_mask].argmax(dim=1)\n",
    "        true = data.y[data.test_mask]\n",
    "        report = classification_report(true.cpu(), pred.cpu(), target_names=[\"Normal\", \"Attack\"], output_dict=True,\n",
    "                                       zero_division=0)\n",
    "        return report['accuracy'], report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "# Grid Search Parameters\n",
    "hidden_sizes = [8, 16, 32]\n",
    "learning_rates = [0.01, 0.02, 0.03]\n",
    "epochs_list = [100, 200, 150]\n",
    "\n",
    "grid = list(product(hidden_sizes, learning_rates, epochs_list))\n",
    "\n",
    "best_f1 = -1\n",
    "best_params = None\n",
    "\n",
    "# Grid Search Execution for GraphSAGE\n",
    "for hidden, lr, epochs in grid:\n",
    "    torch.manual_seed(42)\n",
    "    model = GraphSAGE(2, hidden, 2)\n",
    "    acc, f1 = train(model, data, epochs=epochs, lr=lr)\n",
    "    print(f\"GraphSAGE(hid={hidden}, lr={lr}, epochs={epochs}) → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = (hidden, lr, epochs)\n",
    "\n",
    "print(\n",
    "    f\"\\nBest GraphSAGE config: hidden={best_params[0]}, lr={best_params[1]}, epochs={best_params[2]} with F1={best_f1:.4f}\")"
   ],
   "id": "86c554547c76f42a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
