{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grid Search ",
   "id": "da6d540e1af24f20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:53:02.713921Z",
     "start_time": "2025-05-07T15:52:19.875488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import networkx as nx\n",
    "\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../datasets/train_test_network.csv\")\n",
    "\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    src_ip = row['src_ip']\n",
    "    dst_ip = row['dst_ip']\n",
    "\n",
    "    G.add_edge(\n",
    "        src_ip, dst_ip,\n",
    "        key=\"flow\",\n",
    "        proto=row.get(\"proto\"),\n",
    "        service=row.get(\"service\"),\n",
    "        duration=row.get(\"duration\"),\n",
    "        src_bytes=row.get(\"src_bytes\"),\n",
    "        dst_bytes=row.get(\"dst_bytes\"),\n",
    "        conn_state=row.get(\"conn_state\"),\n",
    "        label=row.get(\"label\"),\n",
    "        attack_type=row.get(\"type\")\n",
    "    )\n",
    "\n",
    "    if pd.notna(row.get(\"dns_query\")):\n",
    "        dns_domain = row[\"dns_query\"]\n",
    "        G.add_edge(\n",
    "            src_ip, dns_domain,\n",
    "            key=\"dns_query\",\n",
    "            qclass=row.get(\"dns_qclass\"),\n",
    "            qtype=row.get(\"dns_qtype\"),\n",
    "            rcode=row.get(\"dns_rcode\"),\n",
    "            dns_AA=row.get(\"dns_AA\"),\n",
    "            dns_RD=row.get(\"dns_RD\"),\n",
    "            dns_RA=row.get(\"dns_RA\"),\n",
    "            dns_rejected=row.get(\"dns_rejected\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"http_uri\")):\n",
    "        http_target = row[\"http_uri\"]\n",
    "        G.add_edge(\n",
    "            src_ip, http_target,\n",
    "            key=\"http_request\",\n",
    "            method=row.get(\"http_method\"),\n",
    "            version=row.get(\"http_version\"),\n",
    "            status_code=row.get(\"http_status_code\"),\n",
    "            trans_depth=row.get(\"http_trans_depth\"),\n",
    "            req_body_len=row.get(\"http_request_body_len\"),\n",
    "            resp_body_len=row.get(\"http_response_body_len\"),\n",
    "            user_agent=row.get(\"http_user_agent\"),\n",
    "            orig_mime=row.get(\"http_orig_mime_types\"),\n",
    "            resp_mime=row.get(\"http_resp_mime_types\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"ssl_subject\")):\n",
    "        G.add_edge(\n",
    "            src_ip, row[\"ssl_subject\"],\n",
    "            key=\"ssl_subject\",\n",
    "            ssl_version=row.get(\"ssl_version\"),\n",
    "            ssl_cipher=row.get(\"ssl_cipher\"),\n",
    "            ssl_resumed=row.get(\"ssl_resumed\"),\n",
    "            ssl_established=row.get(\"ssl_established\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"ssl_issuer\")):\n",
    "        G.add_edge(\n",
    "            src_ip, row[\"ssl_issuer\"],\n",
    "            key=\"ssl_issuer\",\n",
    "            ssl_version=row.get(\"ssl_version\"),\n",
    "            ssl_cipher=row.get(\"ssl_cipher\"),\n",
    "            ssl_resumed=row.get(\"ssl_resumed\"),\n",
    "            ssl_established=row.get(\"ssl_established\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"weird_name\")):\n",
    "        G.add_edge(\n",
    "            src_ip, row[\"weird_name\"],\n",
    "            key=\"protocol_violation\",\n",
    "            weird_addl=row.get(\"weird_addl\"),\n",
    "            weird_notice=row.get(\"weird_notice\")\n",
    "        )\n",
    "\n",
    "print(f\"Graph built with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "print(\"Edge types (views) include:\", set(k for _, _, k in G.edges(keys=True)))"
   ],
   "id": "5a0b817c7bed6896",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph built with 1605 nodes and 2554 edges.\n",
      "Edge types (views) include: {'dns_query', 'http_request', 'ssl_issuer', 'protocol_violation', 'flow', 'ssl_subject'}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:53:02.782075Z",
     "start_time": "2025-05-07T15:53:02.720496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert flow_G (DiGraph) to PyG format\n",
    "ip_nodes = [n for n in G.nodes if isinstance(n, str) and '.' in n]\n",
    "\n",
    "node_to_idx = {node: i for i, node in enumerate(ip_nodes)}\n",
    "edge_index = []\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for node in ip_nodes:\n",
    "    out_deg = len([1 for _, _, k in G.out_edges(node, keys=True) if k == \"flow\"])\n",
    "    in_deg = len([1 for _, _, k in G.in_edges(node, keys=True) if k == \"flow\"])\n",
    "\n",
    "    features.append([in_deg, out_deg])\n",
    "\n",
    "    label = \"Normal\"\n",
    "    for _, _, k, d in G.out_edges(node, keys=True, data=True):\n",
    "        if k == \"flow\" and d.get(\"label\"):\n",
    "            label = \"Attack\" if str(d[\"label\"]).lower() != \"normal\" else \"Normal\"\n",
    "            break\n",
    "    labels.append(label)\n",
    "\n",
    "# Encode features and labels\n",
    "X = StandardScaler().fit_transform(features)\n",
    "y = LabelEncoder().fit_transform(labels)\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Build edge index\n",
    "for u, v in G.edges():\n",
    "    if u in node_to_idx and v in node_to_idx:\n",
    "        edge_index.append([node_to_idx[u], node_to_idx[v]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Define PyG Data\n",
    "data = Data(x=X, edge_index=edge_index, y=y)\n",
    "\n",
    "# Split train/test\n",
    "torch.manual_seed(42)\n",
    "num_nodes = data.num_nodes\n",
    "perm = torch.randperm(num_nodes)\n",
    "train_idx = perm[:int(0.8 * num_nodes)]\n",
    "test_idx = perm[int(0.8 * num_nodes):]\n",
    "\n",
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train_idx] = True\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test_idx] = True\n",
    "\n",
    "\n",
    "# Convert flow_G (DiGraph) to PyG format\n",
    "ip_nodes = [n for n in G.nodes if isinstance(n, str) and '.' in n]\n",
    "\n",
    "node_to_idx = {node: i for i, node in enumerate(ip_nodes)}\n",
    "edge_index = []\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for node in ip_nodes:\n",
    "    out_deg = len([1 for _, _, k in G.out_edges(node, keys=True) if k == \"flow\"])\n",
    "    in_deg = len([1 for _, _, k in G.in_edges(node, keys=True) if k == \"flow\"])\n",
    "\n",
    "    features.append([in_deg, out_deg])\n",
    "\n",
    "    label = \"Normal\"\n",
    "    for _, _, k, d in G.out_edges(node, keys=True, data=True):\n",
    "        if k == \"flow\" and d.get(\"label\"):\n",
    "            label = \"Attack\" if str(d[\"label\"]).lower() != \"normal\" else \"Normal\"\n",
    "            break\n",
    "    labels.append(label)\n",
    "\n",
    "# Encode features and labels\n",
    "X = StandardScaler().fit_transform(features)\n",
    "y = LabelEncoder().fit_transform(labels)\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Build edge index\n",
    "for u, v in G.edges():\n",
    "    if u in node_to_idx and v in node_to_idx:\n",
    "        edge_index.append([node_to_idx[u], node_to_idx[v]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Define PyG Data\n",
    "data = Data(x=X, edge_index=edge_index, y=y)\n",
    "\n",
    "# Split train/test\n",
    "torch.manual_seed(42)\n",
    "num_nodes = data.num_nodes\n",
    "perm = torch.randperm(num_nodes)\n",
    "train_idx = perm[:int(0.8 * num_nodes)]\n",
    "test_idx = perm[int(0.8 * num_nodes):]\n",
    "\n",
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train_idx] = True\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test_idx] = True\n"
   ],
   "id": "76e4e0112ee59f0c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:53:11.438064Z",
     "start_time": "2025-05-07T15:53:02.998586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, data, train_mask, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def test(model, data, test_mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        preds = logits[test_mask].argmax(dim=1).cpu()\n",
    "        labels = data.y[test_mask].cpu()\n",
    "\n",
    "    return (\n",
    "        accuracy_score(labels, preds),\n",
    "        precision_score(labels, preds, zero_division=0),\n",
    "        recall_score(labels, preds, zero_division=0),\n",
    "        f1_score(labels, preds, zero_division=0),\n",
    "    )\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "\n",
    "def run_holdout(data, test_sizes=None):\n",
    "    if test_sizes is None:\n",
    "        test_sizes = [0.1, 0.3, 0.5]\n",
    "    results = []\n",
    "    X = data.x.cpu().numpy()\n",
    "    y = data.y.cpu().numpy()\n",
    "\n",
    "    for test_size in test_sizes:\n",
    "        train_idx, test_idx = train_test_split(\n",
    "            range(len(y)), test_size=test_size, stratify=y, random_state=42\n",
    "        )\n",
    "        train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "        test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "        train_mask[train_idx] = True\n",
    "        test_mask[test_idx] = True\n",
    "\n",
    "        model = GraphSAGE(data.num_node_features, 32, int(data.y.max().item()) + 1).to(data.x.device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(100):\n",
    "            train(model, data, train_mask, optimizer, criterion)\n",
    "\n",
    "        acc, prec, rec, f1 = test(model, data, test_mask)\n",
    "        label = f\"{int((1 - test_size) * 100)}/{int(test_size * 100)}\"\n",
    "        results.append((label, acc, prec, rec, f1))\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_cv(data, splits=None):\n",
    "    if splits is None:\n",
    "        splits = [5, 10]\n",
    "    results = []\n",
    "    X = data.x.cpu().numpy()\n",
    "    y = data.y.cpu().numpy()\n",
    "\n",
    "    for k in splits:\n",
    "        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        accs, precs, recs, f1s = [], [], [], []\n",
    "\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "            test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "            train_mask[train_idx] = True\n",
    "            test_mask[test_idx] = True\n",
    "\n",
    "            model = GraphSAGE(data.num_node_features, 32, int(data.y.max().item()) + 1).to(data.x.device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            for epoch in range(100):\n",
    "                train(model, data, train_mask, optimizer, criterion)\n",
    "\n",
    "            acc, prec, rec, f1 = test(model, data, test_mask)\n",
    "            accs.append(acc)\n",
    "            precs.append(prec)\n",
    "            recs.append(rec)\n",
    "            f1s.append(f1)\n",
    "\n",
    "        results.append((str(k), sum(accs) / k, sum(precs) / k, sum(recs) / k, sum(f1s) / k))\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run evaluations\n",
    "holdout_results = run_holdout(data)\n",
    "cv_results = run_cv(data)\n",
    "\n",
    "print(\"Split/CV,Accuracy,precision,recal,f1-score\")\n",
    "for r in holdout_results + cv_results:\n",
    "    print(f\"{r[0]},{r[1]:.4f},{r[2]:.4f},{r[3]:.4f},{r[4]:.4f}\")"
   ],
   "id": "6a4ee85fae72f804",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split/CV,Accuracy,precision,recal,f1-score\n",
      "90/10,0.9925,0.9924,1.0000,0.9962\n",
      "70/30,0.9950,0.9949,1.0000,0.9974\n",
      "50/50,0.9909,0.9909,1.0000,0.9954\n",
      "5,0.9887,0.9894,0.9992,0.9943\n",
      "10,0.9917,0.9924,0.9992,0.9958\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T15:54:09.652249Z",
     "start_time": "2025-05-07T15:53:11.470643Z"
    }
   },
   "source": [
    "# Assume y is your torch tensor of labels (0 = Normal, 1 = Attack)\n",
    "normal_idx = (y == 0).nonzero(as_tuple=True)[0]\n",
    "attack_idx = (y == 1).nonzero(as_tuple=True)[0]\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Undersample Attack class to match Normal class count\n",
    "num_normals = len(normal_idx)\n",
    "undersampled_attack_idx = attack_idx[torch.randperm(len(attack_idx))[:num_normals]]\n",
    "\n",
    "# Combine and shuffle the balanced indices\n",
    "balanced_train_idx = torch.cat([normal_idx, undersampled_attack_idx])\n",
    "balanced_train_idx = balanced_train_idx[torch.randperm(len(balanced_train_idx))]\n",
    "\n",
    "# Split into train/test (e.g., 80/20 split)\n",
    "train_size = int(0.8 * len(balanced_train_idx))\n",
    "train_idx = balanced_train_idx[:train_size]\n",
    "test_idx = balanced_train_idx[train_size:]  # optional; could use all data for testing\n",
    "\n",
    "# Create masks\n",
    "data.train_mask = torch.zeros(y.size(0), dtype=torch.bool)\n",
    "data.train_mask[train_idx] = True\n",
    "\n",
    "data.test_mask = torch.zeros(y.size(0), dtype=torch.bool)\n",
    "data.test_mask[test_idx] = True\n",
    "from itertools import product\n",
    "from sklearn.metrics import classification_report\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# GCN Model Definition\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Compute class weights based on imbalance\n",
    "def get_class_weights(y):\n",
    "    counts = torch.bincount(y)\n",
    "    weights = 1.0 / counts.float()\n",
    "    weights = weights * (len(y) / weights.sum())  # normalize to sum ~ num_classes\n",
    "    return weights\n",
    "\n",
    "\n",
    "# Training Function (with class weighting)\n",
    "def train(model, data, epochs=100, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    class_weights = get_class_weights(data.y[data.train_mask]).to(data.x.device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask], weight=class_weights)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        pred = logits[data.test_mask].argmax(dim=1)\n",
    "        true = data.y[data.test_mask]\n",
    "        report = classification_report(true.cpu(), pred.cpu(), target_names=[\"Normal\", \"Attack\"], output_dict=True,\n",
    "                                       zero_division=0)\n",
    "        return report['accuracy'], report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "# Grid Search Parameters\n",
    "hidden_sizes = [8, 16, 32, 64]\n",
    "learning_rates = [0.01, 0.005, 0.001]\n",
    "epochs_list = [50, 100]\n",
    "\n",
    "grid = list(product(hidden_sizes, learning_rates, epochs_list))\n",
    "\n",
    "best_f1 = -1\n",
    "best_params = None\n",
    "\n",
    "# Grid Search Execution\n",
    "for hidden, lr, epochs in grid:\n",
    "    torch.manual_seed(42)\n",
    "    model = GCN(2, hidden, 2)\n",
    "    acc, f1 = train(model, data, epochs=epochs, lr=lr)\n",
    "    print(f\"GCN(hid={hidden}, lr={lr}, epochs={epochs}) → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = (hidden, lr, epochs)\n",
    "\n",
    "print(f\"\\nBest GCN config: hidden={best_params[0]}, lr={best_params[1]}, epochs={best_params[2]} with F1={best_f1:.4f}\")\n",
    "## CV and Grid-Search for GCN\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# GCN Model Definition\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Train function (no class weighting needed since we balanced the folds)\n",
    "def train(model, data, train_idx, test_idx, epochs=100, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.train_mask[train_idx] = True\n",
    "    data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    data.test_mask[test_idx] = True\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        pred = logits[data.test_mask].argmax(dim=1)\n",
    "        true = data.y[data.test_mask]\n",
    "        report = classification_report(true.cpu(), pred.cpu(), target_names=[\"Normal\", \"Attack\"], output_dict=True,\n",
    "                                       zero_division=0)\n",
    "        return report['accuracy'], report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "# Create balanced dataset (as before)\n",
    "normal_idx = (y == 0).nonzero(as_tuple=True)[0]\n",
    "attack_idx = (y == 1).nonzero(as_tuple=True)[0]\n",
    "num_normals = len(normal_idx)\n",
    "undersampled_attack_idx = attack_idx[torch.randperm(len(attack_idx))[:num_normals]]\n",
    "balanced_idx = torch.cat([normal_idx, undersampled_attack_idx])\n",
    "balanced_idx = balanced_idx[torch.randperm(len(balanced_idx))]\n",
    "\n",
    "X_np = data.x[balanced_idx].cpu().numpy()  # just to satisfy StratifiedKFold\n",
    "y_np = y[balanced_idx].cpu().numpy()\n",
    "\n",
    "# Grid Search with Cross-Validation\n",
    "hidden_sizes = [8, 16]\n",
    "learning_rates = [0.02, 0.03, 0.05]\n",
    "epochs_list = [50, 100, 200]\n",
    "grid = list(product(hidden_sizes, learning_rates, epochs_list))\n",
    "\n",
    "best_f1 = -1\n",
    "best_params = None\n",
    "\n",
    "for hidden, lr, epochs in grid:\n",
    "    fold_f1s = []\n",
    "    fold_acc = []\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx_np, test_idx_np in skf.split(X_np, y_np):\n",
    "        train_idx = balanced_idx[train_idx_np]\n",
    "        test_idx = balanced_idx[test_idx_np]\n",
    "\n",
    "        torch.manual_seed(42)\n",
    "        model = GCN(2, hidden, 2)\n",
    "        acc, f1 = train(model, data, train_idx, test_idx, epochs=epochs, lr=lr)\n",
    "        fold_f1s.append(f1)\n",
    "        fold_acc.append(acc)\n",
    "\n",
    "    avg_f1 = np.mean(fold_f1s)\n",
    "    avg_acc = np.mean(fold_acc)\n",
    "    print(f\"GCN(hid={hidden}, lr={lr}, epochs={epochs}) → CV acc: {avg_acc:.4f}, F1: {avg_f1:.4f}\")\n",
    "\n",
    "    if avg_f1 > best_f1:\n",
    "        best_f1 = avg_f1\n",
    "        best_params = (hidden, lr, epochs)\n",
    "\n",
    "print(\n",
    "    f\"\\nBest GCN config: hidden={best_params[0]}, lr={best_params[1]}, epochs={best_params[2]} with CV F1={best_f1:.4f}\")\n",
    "## Grid Search with CV on GraphSAGE\n",
    "from itertools import product\n",
    "from sklearn.metrics import classification_report\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# GraphSAGE Model Definition\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Compute class weights based on imbalance\n",
    "def get_class_weights(y):\n",
    "    counts = torch.bincount(y)\n",
    "    weights = 1.0 / counts.float()\n",
    "    weights = weights * (len(y) / weights.sum())  # normalize\n",
    "    return weights\n",
    "\n",
    "\n",
    "# Training Function (same logic)\n",
    "def train(model, data, epochs=100, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    class_weights = get_class_weights(data.y[data.train_mask]).to(data.x.device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask], weight=class_weights)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        pred = logits[data.test_mask].argmax(dim=1)\n",
    "        true = data.y[data.test_mask]\n",
    "        report = classification_report(true.cpu(), pred.cpu(), target_names=[\"Normal\", \"Attack\"], output_dict=True,\n",
    "                                       zero_division=0)\n",
    "        return report['accuracy'], report['weighted avg']['f1-score']\n",
    "\n",
    "\n",
    "# Grid Search Parameters\n",
    "hidden_sizes = [8, 16, 32]\n",
    "learning_rates = [0.01, 0.02, 0.03]\n",
    "epochs_list = [100, 200, 150]\n",
    "\n",
    "grid = list(product(hidden_sizes, learning_rates, epochs_list))\n",
    "\n",
    "best_f1 = -1\n",
    "best_params = None\n",
    "\n",
    "# Grid Search Execution for GraphSAGE\n",
    "for hidden, lr, epochs in grid:\n",
    "    torch.manual_seed(42)\n",
    "    model = GraphSAGE(2, hidden, 2)\n",
    "    acc, f1 = train(model, data, epochs=epochs, lr=lr)\n",
    "    print(f\"GraphSAGE(hid={hidden}, lr={lr}, epochs={epochs}) → Acc: {acc:.4f}, F1: {f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = (hidden, lr, epochs)\n",
    "\n",
    "print(\n",
    "    f\"\\nBest GraphSAGE config: hidden={best_params[0]}, lr={best_params[1]}, epochs={best_params[2]} with F1={best_f1:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(hid=8, lr=0.01, epochs=50) → Acc: 0.7500, F1: 0.7083\n",
      "GCN(hid=8, lr=0.01, epochs=100) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=8, lr=0.005, epochs=50) → Acc: 0.7500, F1: 0.7083\n",
      "GCN(hid=8, lr=0.005, epochs=100) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=8, lr=0.001, epochs=50) → Acc: 0.1250, F1: 0.0833\n",
      "GCN(hid=8, lr=0.001, epochs=100) → Acc: 0.1250, F1: 0.0833\n",
      "GCN(hid=16, lr=0.01, epochs=50) → Acc: 0.7500, F1: 0.7083\n",
      "GCN(hid=16, lr=0.01, epochs=100) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=16, lr=0.005, epochs=50) → Acc: 0.7500, F1: 0.7083\n",
      "GCN(hid=16, lr=0.005, epochs=100) → Acc: 0.7500, F1: 0.7083\n",
      "GCN(hid=16, lr=0.001, epochs=50) → Acc: 0.1250, F1: 0.0833\n",
      "GCN(hid=16, lr=0.001, epochs=100) → Acc: 0.1250, F1: 0.0833\n",
      "GCN(hid=32, lr=0.01, epochs=50) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=32, lr=0.01, epochs=100) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=32, lr=0.005, epochs=50) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=32, lr=0.005, epochs=100) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=32, lr=0.001, epochs=50) → Acc: 0.7500, F1: 0.7500\n",
      "GCN(hid=32, lr=0.001, epochs=100) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=64, lr=0.01, epochs=50) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=64, lr=0.01, epochs=100) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=64, lr=0.005, epochs=50) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=64, lr=0.005, epochs=100) → Acc: 0.8750, F1: 0.8682\n",
      "GCN(hid=64, lr=0.001, epochs=50) → Acc: 0.7500, F1: 0.7500\n",
      "GCN(hid=64, lr=0.001, epochs=100) → Acc: 0.8750, F1: 0.8682\n",
      "\n",
      "Best GCN config: hidden=8, lr=0.01, epochs=100 with F1=0.8682\n",
      "GCN(hid=8, lr=0.02, epochs=50) → CV acc: 0.7393, F1: 0.7216\n",
      "GCN(hid=8, lr=0.02, epochs=100) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=8, lr=0.02, epochs=200) → CV acc: 0.7393, F1: 0.7276\n",
      "GCN(hid=8, lr=0.03, epochs=50) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=8, lr=0.03, epochs=100) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=8, lr=0.03, epochs=200) → CV acc: 0.7143, F1: 0.7022\n",
      "GCN(hid=8, lr=0.05, epochs=50) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=8, lr=0.05, epochs=100) → CV acc: 0.7929, F1: 0.7794\n",
      "GCN(hid=8, lr=0.05, epochs=200) → CV acc: 0.6893, F1: 0.6743\n",
      "GCN(hid=16, lr=0.02, epochs=50) → CV acc: 0.7143, F1: 0.6949\n",
      "GCN(hid=16, lr=0.02, epochs=100) → CV acc: 0.7893, F1: 0.7810\n",
      "GCN(hid=16, lr=0.02, epochs=200) → CV acc: 0.7357, F1: 0.7184\n",
      "GCN(hid=16, lr=0.03, epochs=50) → CV acc: 0.7643, F1: 0.7556\n",
      "GCN(hid=16, lr=0.03, epochs=100) → CV acc: 0.7393, F1: 0.7276\n",
      "GCN(hid=16, lr=0.03, epochs=200) → CV acc: 0.7393, F1: 0.7276\n",
      "GCN(hid=16, lr=0.05, epochs=50) → CV acc: 0.7643, F1: 0.7470\n",
      "GCN(hid=16, lr=0.05, epochs=100) → CV acc: 0.7393, F1: 0.7276\n",
      "GCN(hid=16, lr=0.05, epochs=200) → CV acc: 0.7393, F1: 0.7327\n",
      "\n",
      "Best GCN config: hidden=8, lr=0.02, epochs=100 with CV F1=0.7810\n",
      "GraphSAGE(hid=8, lr=0.01, epochs=100) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=8, lr=0.01, epochs=200) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=8, lr=0.01, epochs=150) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=8, lr=0.02, epochs=100) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=8, lr=0.02, epochs=200) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=8, lr=0.02, epochs=150) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=8, lr=0.03, epochs=100) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=8, lr=0.03, epochs=200) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=8, lr=0.03, epochs=150) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=16, lr=0.01, epochs=100) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=16, lr=0.01, epochs=200) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=16, lr=0.01, epochs=150) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=16, lr=0.02, epochs=100) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=16, lr=0.02, epochs=200) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=16, lr=0.02, epochs=150) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=16, lr=0.03, epochs=100) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=16, lr=0.03, epochs=200) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=16, lr=0.03, epochs=150) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=32, lr=0.01, epochs=100) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=32, lr=0.01, epochs=200) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=32, lr=0.01, epochs=150) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=32, lr=0.02, epochs=100) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=32, lr=0.02, epochs=200) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=32, lr=0.02, epochs=150) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=32, lr=0.03, epochs=100) → Acc: 0.7143, F1: 0.7143\n",
      "GraphSAGE(hid=32, lr=0.03, epochs=200) → Acc: 0.8571, F1: 0.8571\n",
      "GraphSAGE(hid=32, lr=0.03, epochs=150) → Acc: 0.8571, F1: 0.8571\n",
      "\n",
      "Best GraphSAGE config: hidden=8, lr=0.01, epochs=100 with F1=0.8571\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
