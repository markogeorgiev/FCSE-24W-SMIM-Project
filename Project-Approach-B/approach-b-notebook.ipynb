{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-05T16:13:28.132661Z",
     "start_time": "2025-05-05T16:13:24.706135Z"
    }
   },
   "source": [
    "!pip install pandas networkx"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Graph Type and Purpose\n",
    "\n",
    "You are constructing a **heterogeneous directed multigraph** using `NetworkX`’s `MultiDiGraph()` to model complex cyber network interactions. This design is particularly effective for advanced cybersecurity applications such as:\n",
    "\n",
    "- **Graph-based threat detection**\n",
    "- **Anomaly identification in multi-modal behaviors**\n",
    "- **Learning embeddings for heterogeneous entities**\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "- **Heterogeneous nodes**  \n",
    "  Represents diverse entities: IP addresses, domain names, HTTP URIs, SSL certificate subjects/issuers, protocol violation types, etc.\n",
    "\n",
    "- **Multi-view relationships**  \n",
    "  Multiple directed edge types between the same pair of nodes allow different interaction views (e.g., flows, DNS queries, HTTP requests).\n",
    "\n",
    "- **Directed edges**  \n",
    "  Encode **temporal or causal flow** (e.g., `src_ip ➝ dst_ip`, `IP ➝ domain`), reflecting who initiated what.\n",
    "\n",
    "# Node Types (Entities)\n",
    "\n",
    "Each node represents a real-world entity, extracted from one or more dataset columns:\n",
    "\n",
    "| Node Type         | Source Column(s)    | Description                                                                 |\n",
    "|-------------------|---------------------|-----------------------------------------------------------------------------|\n",
    "| **IP Address**     | `src_ip`, `dst_ip`  | Devices or interfaces on the network (e.g., `192.168.1.37`).                |\n",
    "| **Domain Name**    | `dns_query`         | Fully qualified domain names queried by IPs (e.g., `www.example.com`).      |\n",
    "| **HTTP URI**       | `http_uri`          | HTTP resource paths (e.g., `/login`, `/index.html`).                        |\n",
    "| **SSL Subject**    | `ssl_subject`       | Distinguished Name of the certificate subject (e.g., `/C=US/O=Let's Encrypt`). |\n",
    "| **SSL Issuer**     | `ssl_issuer`        | Distinguished Name of the certificate issuer (e.g., `/C=US/O=Google Trust Services`). |\n",
    "| **Protocol Violation** | `weird_name`     | Descriptive label of detected anomalies (e.g., `bad_TCP_checksum`).         |\n",
    "\n",
    "---\n",
    "\n",
    "# Edge Types (Views)\n",
    "\n",
    "Each directed edge represents an interaction or behavioral relationship, often enriched with protocol metadata:\n",
    "\n",
    "## 1. `flow` — (IP ➝ IP)\n",
    "\n",
    "Represents a network flow between two IP addresses.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `dst_ip`  \n",
    "- **Attributes:**\n",
    "  - `proto`, `service`, `duration`, `conn_state`\n",
    "  - `src_bytes`, `dst_bytes`\n",
    "  - `label`, `attack_type`\n",
    "\n",
    "**Usefulness:**  \n",
    "Defines the **structural backbone** of the graph, enabling analysis of traffic patterns and attack topologies.\n",
    "\n",
    "## 2. `dns_query` — (IP ➝ Domain Name)\n",
    "\n",
    "Represents a DNS lookup initiated by a host.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `dns_query`  \n",
    "- **Attributes:**\n",
    "  - `qclass`, `qtype`, `rcode`\n",
    "  - `dns_AA`, `dns_RD`, `dns_RA`, `dns_rejected`\n",
    "\n",
    "**Usefulness:**  \n",
    "Reveals **host intent** and can indicate access to suspicious or malicious domains.\n",
    "\n",
    "## 3. `http_request` — (IP ➝ HTTP URI)\n",
    "\n",
    "Captures web resource requests made by a host.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `http_uri`  \n",
    "- **Attributes:**\n",
    "  - `method`, `version`, `status_code`\n",
    "  - `trans_depth`, `req_body_len`, `resp_body_len`\n",
    "  - `user_agent`, `orig_mime`, `resp_mime`\n",
    "\n",
    "**Usefulness:**  \n",
    "Reflects **web behavior**; useful for detecting scanning, reconnaissance, and probing activity.\n",
    "\n",
    "## 4. `protocol_violation` — (IP ➝ Violation Label)\n",
    "\n",
    "Links an IP to a protocol anomaly observed during communication.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `weird_name`  \n",
    "- **Attributes:**\n",
    "  - `weird_addl`, `weird_notice`\n",
    "\n",
    "**Usefulness:**  \n",
    "Highlights **anomalous or misconfigured hosts**. Many such events are early indicators of compromise or malicious activity.\n",
    "\n",
    "# Semantic Graph Properties\n",
    "\n",
    "- **IP nodes are central:**  \n",
    "  Most interaction types originate from or are directed to IP addresses, making them critical in graph topology.\n",
    "\n",
    "- **Multi-modal behavioral modeling:**  \n",
    "  Combines HTTP, DNS, SSL, and flow-level information into one unified representation.\n",
    "\n",
    "- **Multi-view learning ready:**  \n",
    "  The graph supports training models on **protocol-specific subgraphs or jointly across views**.\n",
    "\n",
    "- **Temporal/causal interpretation:**  \n",
    "  Directed edges preserve **who initiated the interaction**, enabling traceability and behavioral profiling.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "860ea483da168a2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Community Detection\n",
    "Apply clustering or community detection algorithms on specific views:\n",
    "- flow → group IPs that communicate frequently\n",
    "- dns_query → group IPs that query similar domains (suspicious beaconing behavior?)\n",
    "- http_request → group clients based on similar URLs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "478216e2d53ca720"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Node Centrality Analysis\n",
    "Compute betweenness centrality, eigenvector centrality, or PageRank on:\n",
    "- Flow view → who routes/relays the most traffic?\n",
    "- DNS view → which domains are queried the most?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed4043d586e09e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Flow view → who routes/relays the most traffic?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e061ebe6b8f11c8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "DNS view → which domains are queried the most?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afb28a6471b9f94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TODO: DIMKA\n",
    "Write the code for \n",
    "### 1. Community Detection\n",
    "Apply clustering or community detection algorithms on specific views:\n",
    "- flow → group IPs that communicate frequently\n",
    "- dns_query → group IPs that query similar domains (suspicious beaconing behavior?)\n",
    "- http_request → group clients based on similar URLs\n",
    "\n",
    "### 2. Node Centrality Analysis\n",
    "Compute betweenness centrality, eigenvector centrality, or PageRank on:\n",
    "- Flow view → who routes/relays the most traffic?\n",
    "- DNS view → which domains are queried the most?"
   ],
   "id": "fa54a593b7eff982"
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T14:56:16.288201Z",
     "start_time": "2025-05-07T14:56:09.471425Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: torch_geometric in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch) (80.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch_geometric) (3.11.18)\n",
      "Requirement already satisfied: numpy in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch_geometric) (2.2.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch_geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch_geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from torch_geometric) (4.67.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from aiohttp->torch_geometric) (1.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from requests->torch_geometric) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from requests->torch_geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from requests->torch_geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from requests->torch_geometric) (2025.4.26)\n",
      "Requirement already satisfied: colorama in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": "!pip install torch torch_geometric",
   "id": "62fd61aab987486a"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import networkx as nx\n",
    "\n",
    "df = pd.read_csv(\"../datasets/train_test_network.csv\")\n",
    "\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    src_ip = row['src_ip']\n",
    "    dst_ip = row['dst_ip']\n",
    "\n",
    "    G.add_edge(\n",
    "        src_ip, dst_ip,\n",
    "        key=\"flow\",\n",
    "        proto=row.get(\"proto\"),\n",
    "        service=row.get(\"service\"),\n",
    "        duration=row.get(\"duration\"),\n",
    "        src_bytes=row.get(\"src_bytes\"),\n",
    "        dst_bytes=row.get(\"dst_bytes\"),\n",
    "        conn_state=row.get(\"conn_state\"),\n",
    "        label=row.get(\"label\"),\n",
    "        attack_type=row.get(\"type\")\n",
    "    )\n",
    "\n",
    "    if pd.notna(row.get(\"dns_query\")):\n",
    "        dns_domain = row[\"dns_query\"]\n",
    "        G.add_edge(\n",
    "            src_ip, dns_domain,\n",
    "            key=\"dns_query\",\n",
    "            qclass=row.get(\"dns_qclass\"),\n",
    "            qtype=row.get(\"dns_qtype\"),\n",
    "            rcode=row.get(\"dns_rcode\"),\n",
    "            dns_AA=row.get(\"dns_AA\"),\n",
    "            dns_RD=row.get(\"dns_RD\"),\n",
    "            dns_RA=row.get(\"dns_RA\"),\n",
    "            dns_rejected=row.get(\"dns_rejected\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"http_uri\")):\n",
    "        http_target = row[\"http_uri\"]\n",
    "        G.add_edge(\n",
    "            src_ip, http_target,\n",
    "            key=\"http_request\",\n",
    "            method=row.get(\"http_method\"),\n",
    "            version=row.get(\"http_version\"),\n",
    "            status_code=row.get(\"http_status_code\"),\n",
    "            trans_depth=row.get(\"http_trans_depth\"),\n",
    "            req_body_len=row.get(\"http_request_body_len\"),\n",
    "            resp_body_len=row.get(\"http_response_body_len\"),\n",
    "            user_agent=row.get(\"http_user_agent\"),\n",
    "            orig_mime=row.get(\"http_orig_mime_types\"),\n",
    "            resp_mime=row.get(\"http_resp_mime_types\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"ssl_subject\")):\n",
    "        G.add_edge(\n",
    "            src_ip, row[\"ssl_subject\"],\n",
    "            key=\"ssl_subject\",\n",
    "            ssl_version=row.get(\"ssl_version\"),\n",
    "            ssl_cipher=row.get(\"ssl_cipher\"),\n",
    "            ssl_resumed=row.get(\"ssl_resumed\"),\n",
    "            ssl_established=row.get(\"ssl_established\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"ssl_issuer\")):\n",
    "        G.add_edge(\n",
    "            src_ip, row[\"ssl_issuer\"],\n",
    "            key=\"ssl_issuer\",\n",
    "            ssl_version=row.get(\"ssl_version\"),\n",
    "            ssl_cipher=row.get(\"ssl_cipher\"),\n",
    "            ssl_resumed=row.get(\"ssl_resumed\"),\n",
    "            ssl_established=row.get(\"ssl_established\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"weird_name\")):\n",
    "        G.add_edge(\n",
    "            src_ip, row[\"weird_name\"],\n",
    "            key=\"protocol_violation\",\n",
    "            weird_addl=row.get(\"weird_addl\"),\n",
    "            weird_notice=row.get(\"weird_notice\")\n",
    "        )\n",
    "\n",
    "print(f\"Graph built with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "print(\"Edge types (views) include:\", set(k for _, _, k in G.edges(keys=True)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T15:05:31.997238Z",
     "start_time": "2025-05-07T15:04:54.097826Z"
    }
   },
   "id": "ec1b250d5a72a1d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph built with 1605 nodes and 2554 edges.\n",
      "Edge types (views) include: {'dns_query', 'protocol_violation', 'http_request', 'ssl_subject', 'ssl_issuer', 'flow'}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:07:25.444209Z",
     "start_time": "2025-05-07T15:07:25.426975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_counts = df['label'].value_counts()\n",
    "print(f\"Label 0 (Normal): {label_counts.get(0, 0)}\")\n",
    "print(f\"Label 1 (Attack): {label_counts.get(1, 0)}\")"
   ],
   "id": "6cbdde30769435e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 (Normal): 50000\n",
      "Label 1 (Attack): 161043\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T14:57:52.111613Z",
     "start_time": "2025-05-07T14:57:48.198245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Convert flow_G (DiGraph) to PyG format\n",
    "ip_nodes = [n for n in G.nodes if isinstance(n, str) and '.' in n]\n",
    "\n",
    "node_to_idx = {node: i for i, node in enumerate(ip_nodes)}\n",
    "edge_index = []\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for node in ip_nodes:\n",
    "    out_deg = len([1 for _, _, k in G.out_edges(node, keys=True) if k == \"flow\"])\n",
    "    in_deg = len([1 for _, _, k in G.in_edges(node, keys=True) if k == \"flow\"])\n",
    "\n",
    "    features.append([in_deg, out_deg])\n",
    "\n",
    "    label = \"Normal\"\n",
    "    for _, _, k, d in G.out_edges(node, keys=True, data=True):\n",
    "        if k == \"flow\" and d.get(\"label\"):\n",
    "            label = \"Attack\" if str(d[\"label\"]).lower() != \"normal\" else \"Normal\"\n",
    "            break\n",
    "    labels.append(label)\n",
    "\n",
    "# Encode features and labels\n",
    "X = StandardScaler().fit_transform(features)\n",
    "y = LabelEncoder().fit_transform(labels)\n",
    "X = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# Build edge index\n",
    "for u, v in G.edges():\n",
    "    if u in node_to_idx and v in node_to_idx:\n",
    "        edge_index.append([node_to_idx[u], node_to_idx[v]])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Define PyG Data\n",
    "data = Data(x=X, edge_index=edge_index, y=y)\n",
    "\n",
    "# Split train/test\n",
    "torch.manual_seed(42)\n",
    "num_nodes = data.num_nodes\n",
    "perm = torch.randperm(num_nodes)\n",
    "train_idx = perm[:int(0.8 * num_nodes)]\n",
    "test_idx = perm[int(0.8 * num_nodes):]\n",
    "\n",
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.train_mask[train_idx] = True\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask[test_idx] = True\n",
    "\n",
    "\n",
    "# GNN Architectures\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=4)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Training and Evaluation\n",
    "def train(model, data, epochs=100, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        pred = logits[data.test_mask].argmax(dim=1)\n",
    "        true = data.y[data.test_mask]\n",
    "        report = classification_report(true.cpu(), pred.cpu(), target_names=[\"Normal\", \"Attack\"], output_dict=True,\n",
    "                                       zero_division=0)\n",
    "        return report\n",
    "\n",
    "\n",
    "# Experiment configurations\n",
    "configs = [\n",
    "    (\"GCN\", GCN(2, 16, 2)),\n",
    "    (\"GCN_deep\", GCN(2, 64, 2)),\n",
    "    (\"GAT\", GAT(2, 8, 2, heads=4)),\n",
    "    (\"GraphSAGE\", GraphSAGE(2, 16, 2)),\n",
    "]\n",
    "\n",
    "for name, model in configs:\n",
    "    report = train(model, data, epochs=100)\n",
    "    acc = report['accuracy']\n",
    "    prec = report['weighted avg']['precision']\n",
    "    rec = report['weighted avg']['recall']\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    print(f\"{name}, {acc:.4f}, {prec:.4f}, {rec:.4f}, {f1:.4f}\")"
   ],
   "id": "d89d46f11f5932be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN, 0.9849, 0.9700, 0.9849, 0.9774\n",
      "GCN_deep, 0.9849, 0.9700, 0.9849, 0.9774\n",
      "GAT, 0.9849, 0.9700, 0.9849, 0.9774\n",
      "GraphSAGE, 0.9887, 0.9888, 0.9887, 0.9853\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Code for Holdouts & Cross-validation",
   "id": "1712ea4f0fe76497"
  },
  {
   "cell_type": "code",
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, data, train_mask, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[train_mask], data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def test(model, data, test_mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        preds = logits[test_mask].argmax(dim=1).cpu()\n",
    "        labels = data.y[test_mask].cpu()\n",
    "\n",
    "    return (\n",
    "        accuracy_score(labels, preds),\n",
    "        precision_score(labels, preds, zero_division=0),\n",
    "        recall_score(labels, preds, zero_division=0),\n",
    "        f1_score(labels, preds, zero_division=0),\n",
    "    )\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "\n",
    "def run_holdout(data, test_sizes=None):\n",
    "    if test_sizes is None:\n",
    "        test_sizes = [0.1, 0.3, 0.5]\n",
    "    results = []\n",
    "    X = data.x.cpu().numpy()\n",
    "    y = data.y.cpu().numpy()\n",
    "\n",
    "    for test_size in test_sizes:\n",
    "        train_idx, test_idx = train_test_split(\n",
    "            range(len(y)), test_size=test_size, stratify=y, random_state=42\n",
    "        )\n",
    "        train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "        test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "        train_mask[train_idx] = True\n",
    "        test_mask[test_idx] = True\n",
    "\n",
    "        model = GraphSAGE(data.num_node_features, 32, int(data.y.max().item()) + 1).to(data.x.device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(100):\n",
    "            train(model, data, train_mask, optimizer, criterion)\n",
    "\n",
    "        acc, prec, rec, f1 = test(model, data, test_mask)\n",
    "        label = f\"{int((1 - test_size) * 100)}/{int(test_size * 100)}\"\n",
    "        results.append((label, acc, prec, rec, f1))\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_cv(data, splits=None):\n",
    "    if splits is None:\n",
    "        splits = [5, 10]\n",
    "    results = []\n",
    "    X = data.x.cpu().numpy()\n",
    "    y = data.y.cpu().numpy()\n",
    "\n",
    "    for k in splits:\n",
    "        skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        accs, precs, recs, f1s = [], [], [], []\n",
    "\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "            test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "            train_mask[train_idx] = True\n",
    "            test_mask[test_idx] = True\n",
    "\n",
    "            model = GraphSAGE(data.num_node_features, 32, int(data.y.max().item()) + 1).to(data.x.device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "            criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "            for epoch in range(100):\n",
    "                train(model, data, train_mask, optimizer, criterion)\n",
    "\n",
    "            acc, prec, rec, f1 = test(model, data, test_mask)\n",
    "            accs.append(acc)\n",
    "            precs.append(prec)\n",
    "            recs.append(rec)\n",
    "            f1s.append(f1)\n",
    "\n",
    "        results.append((str(k), sum(accs) / k, sum(precs) / k, sum(recs) / k, sum(f1s) / k))\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run evaluations\n",
    "holdout_results = run_holdout(data)\n",
    "cv_results = run_cv(data)\n",
    "\n",
    "print(\"Split/CV,Accuracy,precision,recal,f1-score\")\n",
    "for r in holdout_results + cv_results:\n",
    "    print(f\"{r[0]},{r[1]:.4f},{r[2]:.4f},{r[3]:.4f},{r[4]:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T14:58:08.519362Z",
     "start_time": "2025-05-07T14:57:55.995361Z"
    }
   },
   "id": "7d1fccd56c960c2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split/CV,Accuracy,precision,recal,f1-score\n",
      "90/10,0.9925,0.9924,1.0000,0.9962\n",
      "70/30,0.9950,0.9949,1.0000,0.9974\n",
      "50/50,0.9909,0.9924,0.9985,0.9954\n",
      "5,0.9909,0.9909,1.0000,0.9954\n",
      "10,0.9886,0.9909,0.9977,0.9943\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
