{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-05T16:13:28.132661Z",
     "start_time": "2025-05-05T16:13:24.706135Z"
    }
   },
   "source": [
    "!pip install pandas networkx"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marko\\pycharmprojects\\fcse-24w-smim-project\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Graph Type and Purpose\n",
    "\n",
    "You are constructing a **heterogeneous directed multigraph** using `NetworkX`’s `MultiDiGraph()` to model complex cyber network interactions. This design is particularly effective for advanced cybersecurity applications such as:\n",
    "\n",
    "- **Graph-based threat detection**\n",
    "- **Anomaly identification in multi-modal behaviors**\n",
    "- **Learning embeddings for heterogeneous entities**\n",
    "\n",
    "### Key Characteristics\n",
    "\n",
    "- **Heterogeneous nodes**  \n",
    "  Represents diverse entities: IP addresses, domain names, HTTP URIs, SSL certificate subjects/issuers, protocol violation types, etc.\n",
    "\n",
    "- **Multi-view relationships**  \n",
    "  Multiple directed edge types between the same pair of nodes allow different interaction views (e.g., flows, DNS queries, HTTP requests).\n",
    "\n",
    "- **Directed edges**  \n",
    "  Encode **temporal or causal flow** (e.g., `src_ip ➝ dst_ip`, `IP ➝ domain`), reflecting who initiated what.\n",
    "\n",
    "# Node Types (Entities)\n",
    "\n",
    "Each node represents a real-world entity, extracted from one or more dataset columns:\n",
    "\n",
    "| Node Type         | Source Column(s)    | Description                                                                 |\n",
    "|-------------------|---------------------|-----------------------------------------------------------------------------|\n",
    "| **IP Address**     | `src_ip`, `dst_ip`  | Devices or interfaces on the network (e.g., `192.168.1.37`).                |\n",
    "| **Domain Name**    | `dns_query`         | Fully qualified domain names queried by IPs (e.g., `www.example.com`).      |\n",
    "| **HTTP URI**       | `http_uri`          | HTTP resource paths (e.g., `/login`, `/index.html`).                        |\n",
    "| **SSL Subject**    | `ssl_subject`       | Distinguished Name of the certificate subject (e.g., `/C=US/O=Let's Encrypt`). |\n",
    "| **SSL Issuer**     | `ssl_issuer`        | Distinguished Name of the certificate issuer (e.g., `/C=US/O=Google Trust Services`). |\n",
    "| **Protocol Violation** | `weird_name`     | Descriptive label of detected anomalies (e.g., `bad_TCP_checksum`).         |\n",
    "\n",
    "---\n",
    "\n",
    "# Edge Types (Views)\n",
    "\n",
    "Each directed edge represents an interaction or behavioral relationship, often enriched with protocol metadata:\n",
    "\n",
    "## 1. `flow` — (IP ➝ IP)\n",
    "\n",
    "Represents a network flow between two IP addresses.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `dst_ip`  \n",
    "- **Attributes:**\n",
    "  - `proto`, `service`, `duration`, `conn_state`\n",
    "  - `src_bytes`, `dst_bytes`\n",
    "  - `label`, `attack_type`\n",
    "\n",
    "**Usefulness:**  \n",
    "Defines the **structural backbone** of the graph, enabling analysis of traffic patterns and attack topologies.\n",
    "\n",
    "## 2. `dns_query` — (IP ➝ Domain Name)\n",
    "\n",
    "Represents a DNS lookup initiated by a host.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `dns_query`  \n",
    "- **Attributes:**\n",
    "  - `qclass`, `qtype`, `rcode`\n",
    "  - `dns_AA`, `dns_RD`, `dns_RA`, `dns_rejected`\n",
    "\n",
    "**Usefulness:**  \n",
    "Reveals **host intent** and can indicate access to suspicious or malicious domains.\n",
    "\n",
    "## 3. `http_request` — (IP ➝ HTTP URI)\n",
    "\n",
    "Captures web resource requests made by a host.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `http_uri`  \n",
    "- **Attributes:**\n",
    "  - `method`, `version`, `status_code`\n",
    "  - `trans_depth`, `req_body_len`, `resp_body_len`\n",
    "  - `user_agent`, `orig_mime`, `resp_mime`\n",
    "\n",
    "**Usefulness:**  \n",
    "Reflects **web behavior**; useful for detecting scanning, reconnaissance, and probing activity.\n",
    "\n",
    "## 4. `protocol_violation` — (IP ➝ Violation Label)\n",
    "\n",
    "Links an IP to a protocol anomaly observed during communication.\n",
    "\n",
    "- **Source:** `src_ip`  \n",
    "- **Target:** `weird_name`  \n",
    "- **Attributes:**\n",
    "  - `weird_addl`, `weird_notice`\n",
    "\n",
    "**Usefulness:**  \n",
    "Highlights **anomalous or misconfigured hosts**. Many such events are early indicators of compromise or malicious activity.\n",
    "\n",
    "# Semantic Graph Properties\n",
    "\n",
    "- **IP nodes are central:**  \n",
    "  Most interaction types originate from or are directed to IP addresses, making them critical in graph topology.\n",
    "\n",
    "- **Multi-modal behavioral modeling:**  \n",
    "  Combines HTTP, DNS, SSL, and flow-level information into one unified representation.\n",
    "\n",
    "- **Multi-view learning ready:**  \n",
    "  The graph supports training models on **protocol-specific subgraphs or jointly across views**.\n",
    "\n",
    "- **Temporal/causal interpretation:**  \n",
    "  Directed edges preserve **who initiated the interaction**, enabling traceability and behavioral profiling.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "860ea483da168a2b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T13:08:37.674031Z",
     "start_time": "2025-05-06T13:08:02.002059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "df = pd.read_csv(\"../datasets/train_test_network.csv\")\n",
    "\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    src_ip = row['src_ip']\n",
    "    dst_ip = row['dst_ip']\n",
    "\n",
    "    G.add_edge(\n",
    "        src_ip, dst_ip,\n",
    "        key=\"flow\",\n",
    "        proto=row.get(\"proto\"),\n",
    "        service=row.get(\"service\"),\n",
    "        duration=row.get(\"duration\"),\n",
    "        src_bytes=row.get(\"src_bytes\"),\n",
    "        dst_bytes=row.get(\"dst_bytes\"),\n",
    "        conn_state=row.get(\"conn_state\"),\n",
    "        label=row.get(\"label\"),\n",
    "        attack_type=row.get(\"type\")\n",
    "    )\n",
    "\n",
    "    if pd.notna(row.get(\"dns_query\")):\n",
    "        dns_domain = row[\"dns_query\"]\n",
    "        G.add_edge(\n",
    "            src_ip, dns_domain,\n",
    "            key=\"dns_query\",\n",
    "            qclass=row.get(\"dns_qclass\"),\n",
    "            qtype=row.get(\"dns_qtype\"),\n",
    "            rcode=row.get(\"dns_rcode\"),\n",
    "            dns_AA=row.get(\"dns_AA\"),\n",
    "            dns_RD=row.get(\"dns_RD\"),\n",
    "            dns_RA=row.get(\"dns_RA\"),\n",
    "            dns_rejected=row.get(\"dns_rejected\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"http_uri\")):\n",
    "        http_target = row[\"http_uri\"]\n",
    "        G.add_edge(\n",
    "            src_ip, http_target,\n",
    "            key=\"http_request\",\n",
    "            method=row.get(\"http_method\"),\n",
    "            version=row.get(\"http_version\"),\n",
    "            status_code=row.get(\"http_status_code\"),\n",
    "            trans_depth=row.get(\"http_trans_depth\"),\n",
    "            req_body_len=row.get(\"http_request_body_len\"),\n",
    "            resp_body_len=row.get(\"http_response_body_len\"),\n",
    "            user_agent=row.get(\"http_user_agent\"),\n",
    "            orig_mime=row.get(\"http_orig_mime_types\"),\n",
    "            resp_mime=row.get(\"http_resp_mime_types\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"ssl_subject\")):\n",
    "        G.add_edge(\n",
    "            src_ip, row[\"ssl_subject\"],\n",
    "            key=\"ssl_subject\",\n",
    "            ssl_version=row.get(\"ssl_version\"),\n",
    "            ssl_cipher=row.get(\"ssl_cipher\"),\n",
    "            ssl_resumed=row.get(\"ssl_resumed\"),\n",
    "            ssl_established=row.get(\"ssl_established\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"ssl_issuer\")):\n",
    "        G.add_edge(\n",
    "            src_ip, row[\"ssl_issuer\"],\n",
    "            key=\"ssl_issuer\",\n",
    "            ssl_version=row.get(\"ssl_version\"),\n",
    "            ssl_cipher=row.get(\"ssl_cipher\"),\n",
    "            ssl_resumed=row.get(\"ssl_resumed\"),\n",
    "            ssl_established=row.get(\"ssl_established\")\n",
    "        )\n",
    "\n",
    "    if pd.notna(row.get(\"weird_name\")):\n",
    "        G.add_edge(\n",
    "            src_ip, row[\"weird_name\"],\n",
    "            key=\"protocol_violation\",\n",
    "            weird_addl=row.get(\"weird_addl\"),\n",
    "            weird_notice=row.get(\"weird_notice\")\n",
    "        )\n",
    "        \n",
    "print(f\"Graph built with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
    "print(\"Edge types (views) include:\", set(k for _, _, k in G.edges(keys=True)))"
   ],
   "id": "fadc84ba5d847590",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph built with 1605 nodes and 2554 edges.\n",
      "Edge types (views) include: {'protocol_violation', 'flow', 'http_request', 'ssl_issuer', 'dns_query', 'ssl_subject'}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T13:09:08.652672Z",
     "start_time": "2025-05-06T13:09:08.648718Z"
    }
   },
   "id": "186d4c21706f00bc",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def print_detailed_classification_report(report):\n",
    "    print(\"Classification Report Summary\\n\")\n",
    "\n",
    "    for label in [\"Normal\", \"Attack\"]:\n",
    "        print(f\"🔹 Class: {label}\")\n",
    "        precision = report[label]['precision']\n",
    "        recall = report[label]['recall']\n",
    "        f1 = report[label]['f1-score']\n",
    "        support = report[label]['support']\n",
    "\n",
    "        print(f\"  - Number of true samples (support): {int(support)}\")\n",
    "        print(f\"  - Precision: {precision:.2f} -> Of all predicted '{label}', {precision:.0%} were correct.\")\n",
    "        print(f\"  - Recall:    {recall:.2f} -> Of all actual '{label}', {recall:.0%} were found.\")\n",
    "        print(f\"  - F1 Score:  {f1:.2f} -> Harmonic mean of precision and recall.\\n\")\n",
    "\n",
    "    print(\"Overall Performance\")\n",
    "    print(f\"  - Accuracy:         {report['accuracy']:.2%} -> Total correct predictions out of all samples.\\n\")\n",
    "    \n",
    "    print(\"  - Macro Avg (equal weight per class):\")\n",
    "    print(f\"    - Precision: {report['macro avg']['precision']:.2f}\")\n",
    "    print(f\"    - Recall:    {report['macro avg']['recall']:.2f}\")\n",
    "    print(f\"    - F1 Score:  {report['macro avg']['f1-score']:.2f}\")\n",
    "\n",
    "    print(\"\\n  - Weighted Avg (weighted by class size):\")\n",
    "    print(f\"    - Precision: {report['weighted avg']['precision']:.2f}\")\n",
    "    print(f\"    - Recall:    {report['weighted avg']['recall']:.2f}\")\n",
    "    print(f\"    - F1 Score:  {report['weighted avg']['f1-score']:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T13:17:17.521226Z",
     "start_time": "2025-05-06T13:17:17.514902Z"
    }
   },
   "id": "941490b7fd43e1fe",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Community Detection\n",
    "Apply clustering or community detection algorithms on specific views:\n",
    "- flow → group IPs that communicate frequently\n",
    "- dns_query → group IPs that query similar domains (suspicious beaconing behavior?)\n",
    "- http_request → group clients based on similar URLs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "478216e2d53ca720"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report Summary\n",
      "\n",
      "🔹 Class: Normal\n",
      "  - Number of true samples (support): 19\n",
      "  - Precision: 1.00 -> Of all predicted 'Normal', 100% were correct.\n",
      "  - Recall:    0.32 -> Of all actual 'Normal', 32% were found.\n",
      "  - F1 Score:  0.48 -> Harmonic mean of precision and recall.\n",
      "\n",
      "🔹 Class: Attack\n",
      "  - Number of true samples (support): 1303\n",
      "  - Precision: 0.99 -> Of all predicted 'Attack', 99% were correct.\n",
      "  - Recall:    1.00 -> Of all actual 'Attack', 100% were found.\n",
      "  - F1 Score:  1.00 -> Harmonic mean of precision and recall.\n",
      "\n",
      "Overall Performance\n",
      "  - Accuracy:         99.02% -> Total correct predictions out of all samples.\n",
      "\n",
      "  - Macro Avg (equal weight per class):\n",
      "    - Precision: 1.00\n",
      "    - Recall:    0.66\n",
      "    - F1 Score:  0.74\n",
      "\n",
      "  - Weighted Avg (weighted by class size):\n",
      "    - Precision: 0.99\n",
      "    - Recall:    0.99\n",
      "    - F1 Score:  0.99\n"
     ]
    }
   ],
   "source": [
    "ip_nodes = [n for n in G.nodes if isinstance(n, str) and '.' in n]  # crude IP filter\n",
    "\n",
    "# Create a feature matrix: in-degree and out-degree from 'flow' edges\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for ip in ip_nodes:\n",
    "    out_deg = len([1 for _, _, k in G.out_edges(ip, keys=True) if k == \"flow\"])\n",
    "    in_deg = len([1 for _, _, k in G.in_edges(ip, keys=True) if k == \"flow\"])\n",
    "    label = None\n",
    "    for _, _, k, d in G.out_edges(ip, keys=True, data=True):\n",
    "        if k == \"flow\" and d.get(\"label\"):\n",
    "            label = d[\"label\"]\n",
    "            break\n",
    "    features.append([in_deg, out_deg])\n",
    "    labels.append(label if label else \"Normal\")\n",
    "\n",
    "X = StandardScaler().fit_transform(features)\n",
    "kmeans = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(X)\n",
    "\n",
    "# Interpret labels\n",
    "cluster_labels = kmeans.labels_\n",
    "true_labels = [\"Attack\" if str(l).lower() != \"normal\" else \"Normal\" for l in labels]\n",
    "\n",
    "# Step 2: Create a mapping from cluster index to predicted label\n",
    "# This assumes only two clusters: 0 and 1\n",
    "df = pd.DataFrame({'cluster': cluster_labels, 'true': true_labels})\n",
    "mapping = {}\n",
    "\n",
    "for cluster_id in np.unique(cluster_labels):\n",
    "    majority_class = df[df['cluster'] == cluster_id]['true'].mode()[0]\n",
    "    mapping[cluster_id] = majority_class\n",
    "\n",
    "# Step 3: Map numeric cluster labels to \"Normal\"/\"Attack\"\n",
    "predicted_labels = [mapping[c] for c in cluster_labels]\n",
    "\n",
    "# Step 4: Classification report\n",
    "report = classification_report(true_labels, predicted_labels, target_names=[\"Normal\", \"Attack\"], output_dict=True)\n",
    "print_detailed_classification_report(report)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T13:17:18.768012Z",
     "start_time": "2025-05-06T13:17:18.715739Z"
    }
   },
   "id": "cacf7ea943849d6f",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Node Centrality Analysis\n",
    "Compute betweenness centrality, eigenvector centrality, or PageRank on:\n",
    "- Flow view → who routes/relays the most traffic?\n",
    "- DNS view → which domains are queried the most?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ed4043d586e09e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Flow view → who routes/relays the most traffic?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e061ebe6b8f11c8d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "105ee731716df979"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow-based Centrality Analysis\n",
      "\n",
      "Top 10 by Betweenness Centrality (Flow):\n",
      "  192.168.1.190: 0.0126\n",
      "  192.168.1.152: 0.0055\n",
      "  192.168.1.193: 0.0044\n",
      "  192.168.1.31: 0.0040\n",
      "  192.168.1.30: 0.0034\n",
      "  192.168.1.195: 0.0034\n",
      "  192.168.1.34: 0.0018\n",
      "  192.168.1.37: 0.0010\n",
      "  192.168.1.33: 0.0010\n",
      "  192.168.1.1: 0.0004\n",
      "\n",
      "Top 10 by PageRank (Flow):\n",
      "  ff02::fb: 0.0081\n",
      "  224.0.0.251: 0.0074\n",
      "  192.168.1.190: 0.0063\n",
      "  192.168.1.255: 0.0049\n",
      "  ff02::1:3: 0.0048\n",
      "  192.168.1.193: 0.0030\n",
      "  192.168.1.31: 0.0029\n",
      "  192.168.1.37: 0.0029\n",
      "  192.168.1.33: 0.0029\n",
      "  224.0.0.252: 0.0028\n",
      "\n",
      "Top 10 by Eigenvector Centrality (Flow):\n",
      "  192.168.1.195: 0.2238\n",
      "  192.168.1.152: 0.1960\n",
      "  192.168.1.190: 0.1865\n",
      "  224.0.0.251: 0.1824\n",
      "  192.168.1.255: 0.1669\n",
      "  117.18.237.29: 0.1616\n",
      "  192.168.1.193: 0.1438\n",
      "  13.35.146.12: 0.1305\n",
      "  192.168.1.1: 0.1162\n",
      "  239.255.255.250: 0.1158\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# FLOW VIEW: Create subgraph for 'flow' edges only\n",
    "flow_edges = [(u, v) for u, v, k in G.edges(keys=True) if k == \"flow\"]\n",
    "flow_G = nx.DiGraph()\n",
    "flow_G.add_edges_from(flow_edges)\n",
    "\n",
    "print(\"Flow-based Centrality Analysis\")\n",
    "\n",
    "# Betweenness Centrality\n",
    "flow_betweenness = nx.betweenness_centrality(flow_G)\n",
    "top_flow_betweenness = sorted(flow_betweenness.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"\\nTop 10 by Betweenness Centrality (Flow):\")\n",
    "for node, score in top_flow_betweenness:\n",
    "    print(f\"  {node}: {score:.4f}\")\n",
    "\n",
    "# PageRank\n",
    "flow_pagerank = nx.pagerank(flow_G, alpha=0.85)\n",
    "top_flow_pagerank = sorted(flow_pagerank.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"\\nTop 10 by PageRank (Flow):\")\n",
    "for node, score in top_flow_pagerank:\n",
    "    print(f\"  {node}: {score:.4f}\")\n",
    "\n",
    "# Eigenvector Centrality (only works on strongly connected graphs or large components)\n",
    "try:\n",
    "    flow_eigen = nx.eigenvector_centrality(flow_G, max_iter=1000)\n",
    "    top_flow_eigen = sorted(flow_eigen.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    print(\"\\nTop 10 by Eigenvector Centrality (Flow):\")\n",
    "    for node, score in top_flow_eigen:\n",
    "        print(f\"  {node}: {score:.4f}\")\n",
    "except nx.PowerIterationFailedConvergence:\n",
    "    print(\"\\nEigenvector centrality failed to converge on flow view.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T13:23:27.185044Z",
     "start_time": "2025-05-06T13:23:26.889347Z"
    }
   },
   "id": "3a02508ec4462ac",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "DNS view → which domains are queried the most?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afb28a6471b9f94"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DNS-based Centrality Analysis\n",
      "\n",
      "Top 10 Queried Domains (by in-degree):\n",
      "  -: 36 queries\n",
      "  _googlecast._tcp.local: 9 queries\n",
      "  shavar.services.mozilla.com: 8 queries\n",
      "  wpad: 7 queries\n",
      "  services.addons.mozilla.org: 7 queries\n",
      "  versioncheck-bg.addons.mozilla.org: 7 queries\n",
      "  detectportal.firefox.com: 6 queries\n",
      "  aus5.mozilla.org: 6 queries\n",
      "  firefox.settings.services.mozilla.com: 6 queries\n",
      "  blocklists.settings.services.mozilla.com: 6 queries\n",
      "\n",
      "Top 10 by PageRank (DNS):\n",
      "  -: 0.0210\n",
      "  _sleep-proxy._udp.local: 0.0027\n",
      "  android.local: 0.0026\n",
      "  isatap: 0.0025\n",
      "  _googlecast._tcp.local: 0.0023\n",
      "  _fb._tcp.local: 0.0022\n",
      "  _raop._tcp.local: 0.0022\n",
      "  desktop-18ss3ba: 0.0021\n",
      "  _ipps._tcp.local: 0.0020\n",
      "  _companion-link._tcp.local: 0.0020\n"
     ]
    }
   ],
   "source": [
    "# DNS VIEW: Create bipartite-like graph of IPs querying domain names\n",
    "dns_edges = [(u, v) for u, v, k in G.edges(keys=True) if k == \"dns_query\"]\n",
    "dns_G = nx.DiGraph()\n",
    "dns_G.add_edges_from(dns_edges)\n",
    "\n",
    "print(\"\\nDNS-based Centrality Analysis\")\n",
    "\n",
    "# In-degree Centrality: How often a domain is queried\n",
    "dns_indegree = dns_G.in_degree()\n",
    "top_domains = sorted(dns_indegree, key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"\\nTop 10 Queried Domains (by in-degree):\")\n",
    "for domain, deg in top_domains:\n",
    "    print(f\"  {domain}: {deg} queries\")\n",
    "\n",
    "# PageRank for domains\n",
    "dns_pagerank = nx.pagerank(dns_G, alpha=0.85)\n",
    "top_dns_pagerank = sorted(dns_pagerank.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"\\nTop 10 by PageRank (DNS):\")\n",
    "for node, score in top_dns_pagerank:\n",
    "    print(f\"  {node}: {score:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-06T13:30:44.657528Z",
     "start_time": "2025-05-06T13:30:44.642991Z"
    }
   },
   "id": "543744cdcafa26c3",
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## TODO: DIMKA\n",
    "Write the code for \n",
    "### 1. Community Detection\n",
    "Apply clustering or community detection algorithms on specific views:\n",
    "- flow → group IPs that communicate frequently\n",
    "- dns_query → group IPs that query similar domains (suspicious beaconing behavior?)\n",
    "- http_request → group clients based on similar URLs\n",
    "\n",
    "### 2. Node Centrality Analysis\n",
    "Compute betweenness centrality, eigenvector centrality, or PageRank on:\n",
    "- Flow view → who routes/relays the most traffic?\n",
    "- DNS view → which domains are queried the most?\n",
    "\n",
    "### 3. Node Feature Extraction for Classification  \n",
    "Use the graph structure to extract features for IP nodes and apply supervised machine learning to classify them as normal or malicious.\n",
    "\n",
    "- Use the existing `label` and `attack_type` attributes from the `flow` view as ground truth.\n",
    "- Generate per-node features across different views to capture behavioral patterns.\n",
    "- Train a classifier (e.g., Random Forest, XGBoost, or MLP) to detect malicious IPs.\n",
    "\n",
    "Feature ideas for each IP node:\n",
    "\n",
    "| Feature                               | Description                                                   |\n",
    "|--------------------------------------|---------------------------------------------------------------|\n",
    "| Degree / in-degree / out-degree      | Number of total/initiated/received connections (flow view)   |\n",
    "| Number of distinct queried domains   | From `dns_query` edges — indicates domain diversity           |\n",
    "| Number of protocol violations        | From `protocol_violation` edges — potential misbehavior       |\n",
    "| Most common HTTP status codes        | From `http_request` edges — could signal probing or scanning  |\n",
    "| Avg. bytes sent/received             | Captures traffic volume per connection                        |\n",
    "| PageRank / betweenness / eigenvector | Centrality in communication network (flow view)               |\n",
    "| Clustering coefficient               | Measures tightness of local communication                     |\n",
    "| Number of SSL subjects or issuers    | Captures breadth of contacted certs (SSL-related views)       |\n",
    "\n",
    "Usefulness: Enables explainable, graph-based threat classification using traditional ML pipelines. Serves as a strong baseline and complements centrality/community detection."
   ],
   "id": "fa54a593b7eff982"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "65fc3e817cc1fe2e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
